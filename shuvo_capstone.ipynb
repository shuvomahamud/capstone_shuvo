{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRtuGyFvtL9_"
   },
   "source": [
    "Motor Vehicle Collisions - Crashes -- https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuK9GoLZUhqr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.pandas.set_option(\"display.max_rows\", None)\n",
    "pd.pandas.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "RJVYvi7hUuK1",
    "outputId": "4c902213-e559-4946-d6bb-30585529330e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df  = pd.read_csv(\"Motor_Vehicle_Collisions.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtRhdVo_wu6p",
    "outputId": "2015e94a-392b-47b1-b74e-e57ed353ebaf"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cawgczQlsjBS"
   },
   "source": [
    "Lets look at the datatype and columns at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "id": "vWzR7gv8vs11",
    "outputId": "1005c1a7-a0f9-449b-c02a-7874d9c670cd"
   },
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lg6JHV2galGu",
    "outputId": "275cac75-2b53-4652-a22d-2fe5a84e08d9"
   },
   "outputs": [],
   "source": [
    "df= df[df['CONTRIBUTING FACTOR VEHICLE 1'].notna()]\n",
    "dfspecified= df[df['CONTRIBUTING FACTOR VEHICLE 1'] !='Unspecified']\n",
    "dfspecified.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Jf6WxY7bLLx"
   },
   "source": [
    "To have look at the Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1rx3CarvAo-",
    "outputId": "431e48c7-1af2-4356-850c-30c034fee632"
   },
   "outputs": [],
   "source": [
    "dfspecified = dfspecified[dfspecified['CONTRIBUTING FACTOR VEHICLE 1'].notna()]\n",
    "dfspecified = pd.DataFrame(dfspecified[dfspecified['LONGITUDE'].notna()])\n",
    "dfspecified = dfspecified[dfspecified['BOROUGH'].notna()]\n",
    "dfspecified = dfspecified[dfspecified['ON STREET NAME'].notna()]\n",
    "#dfspecified.to_csv('output.csv', index= False)\n",
    "\n",
    "# Compute the mean and standard deviation of the latitude column\n",
    "print(\"Mean latitude:\", dfspecified['LATITUDE'].mean())\n",
    "print(\"Standard deviation latitude:\", dfspecified['LATITUDE'].std())\n",
    "\n",
    "# Compute the count and percentage of accidents in each borough\n",
    "borough_counts = dfspecified['BOROUGH'].value_counts()\n",
    "print(borough_counts)\n",
    "borough_percentages = dfspecified['BOROUGH'].value_counts(normalize=True) * 100\n",
    "print(borough_percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nv4bI2XeW5mN",
    "outputId": "6ad78424-56d5-4ec8-d05b-d976481e256d"
   },
   "outputs": [],
   "source": [
    "# Convert the CRASH DATE column to a datetime object\n",
    "dfspecified['CRASH DATE'] = pd.to_datetime(dfspecified['CRASH DATE'])\n",
    "\n",
    "# Create a new column with the day of the week\n",
    "dfspecified['DAY OF WEEK'] = dfspecified['CRASH DATE'].dt.day_name()\n",
    "\n",
    "# Compute the number of accidents per day of the week\n",
    "day_counts = dfspecified['DAY OF WEEK'].value_counts()\n",
    "print(day_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "WumIPYXw1lP5",
    "outputId": "ca2272d2-3a0d-4d63-b429-e716386aff27"
   },
   "outputs": [],
   "source": [
    "dfspecified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ScNwLUYtYA9h",
    "outputId": "2ad468ac-a264-44e8-e1a2-bf1529dcad08"
   },
   "outputs": [],
   "source": [
    "dfspecified = dfspecified[dfspecified['CROSS STREET NAME'].notna()]\n",
    "\n",
    "dfspecified = dfspecified[dfspecified['CONTRIBUTING FACTOR VEHICLE 2'].notna()]\n",
    "\n",
    "dfspecified = dfspecified[dfspecified['VEHICLE TYPE CODE 1'].notna()]\n",
    "\n",
    "dfspecified = dfspecified[dfspecified['VEHICLE TYPE CODE 2'].notna()]\n",
    "\n",
    "dfspecified.loc['NUMBER OF PERSONS INJURED'] = dfspecified['NUMBER OF PERSONS INJURED'].fillna(0)\n",
    "\n",
    "dfspecified.loc['NUMBER OF PERSONS KILLED'] = dfspecified['NUMBER OF PERSONS KILLED'].fillna(0)\n",
    "\n",
    "\n",
    "# Check the updated DataFrame\n",
    "dfspecified.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cK_RvX1riMyY"
   },
   "outputs": [],
   "source": [
    "dfspecified.dropna(subset=['CONTRIBUTING FACTOR VEHICLE 1'], inplace=True)\n",
    "dfspecified.dropna(subset=['CONTRIBUTING FACTOR VEHICLE 2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CedpE4OHaSd-"
   },
   "outputs": [],
   "source": [
    "dfspecified['INJURY_SEVERITY'] = dfspecified['NUMBER OF PERSONS INJURED'] + dfspecified['NUMBER OF PERSONS KILLED'] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKdqB0V1kJMI"
   },
   "outputs": [],
   "source": [
    "def categorize_injury_severity(injury_severity):\n",
    "    if injury_severity == 0:\n",
    "        return 'No Injury'\n",
    "    elif 0 < injury_severity <= 2:\n",
    "        return 'Mild Injury'\n",
    "    elif 2 < injury_severity <= 4:\n",
    "        return 'Moderate Injury'\n",
    "    elif 4 < injury_severity <= 6:\n",
    "        return 'Severe Injury'\n",
    "    else:\n",
    "        return 'Fatal'\n",
    "\n",
    "# Assuming you have already created the 'INJURY_SEVERITY' column\n",
    "dfspecified['INJURY_CATEGORY'] = dfspecified['INJURY_SEVERITY'].apply(categorize_injury_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kexnsNZe-Kr"
   },
   "outputs": [],
   "source": [
    "dfspecified['CRASH TIME'] = pd.to_datetime(dfspecified['CRASH TIME'])\n",
    "\n",
    "# Extract the hour, minute, and second values from CRASH TIME\n",
    "hour = dfspecified['CRASH TIME'].dt.hour\n",
    "minute = dfspecified['CRASH TIME'].dt.minute\n",
    "second = dfspecified['CRASH TIME'].dt.second\n",
    "\n",
    "# Calculate total number of seconds since midnight\n",
    "seconds_since_midnight = hour*3600 + minute*60 + second\n",
    "\n",
    "# Add the new column to the DataFrame\n",
    "dfspecified['SECONDS_SINCE_MIDNIGHT'] = seconds_since_midnight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V51rYyI9Brr7",
    "outputId": "34f6eaba-f4f0-4efd-8c15-683bfee53a02"
   },
   "outputs": [],
   "source": [
    "# Count the occurrences of each contributing factor across all boroughs\n",
    "factor_counts = dfspecified.groupby('CONTRIBUTING FACTOR VEHICLE 1').size().reset_index(name='counts')\n",
    "most_common_factor = factor_counts.sort_values('counts', ascending=False).iloc[0]['CONTRIBUTING FACTOR VEHICLE 1']\n",
    "print(\"The most common contributing factor to car accidents in NYC is:\", most_common_factor)\n",
    "\n",
    "# Count the occurrences of each contributing factor by borough\n",
    "borough_factor_counts = dfspecified.groupby(['BOROUGH', 'CONTRIBUTING FACTOR VEHICLE 1']).size().reset_index(name='counts')\n",
    "borough_most_common_factor = borough_factor_counts[borough_factor_counts['CONTRIBUTING FACTOR VEHICLE 1'] == most_common_factor]\n",
    "print(\"\\nMost common contributing factor by borough:\\n\", borough_most_common_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0QfDN69lyGW"
   },
   "outputs": [],
   "source": [
    "def standardize_street_name(name):\n",
    "    # Convert to uppercase and strip leading/trailing whitespaces\n",
    "    if not isinstance(name, str):\n",
    "      return name\n",
    "    name = name.upper().strip()\n",
    "\n",
    "    # Replace common abbreviations\n",
    "    name = name.replace(' ST.', ' STREET')\n",
    "    name = name.replace(' AVE.', ' AVENUE')\n",
    "    name = name.replace(' BLVD.', ' BOULEVARD')\n",
    "    name = name.replace(' RD.', ' ROAD')\n",
    "    name = name.replace(' PL.', ' PLACE')\n",
    "    name = name.replace(' PKWY.', ' PARKWAY')\n",
    "    name = name.replace(' DR.', ' DRIVE')\n",
    "    name = name.replace(' LN.', ' LANE')\n",
    "    name = name.replace(' CT.', ' COURT')\n",
    "    # Add more replacements as needed\n",
    "\n",
    "    return name\n",
    "\n",
    "# Apply the standardize_street_name function to the 'ON STREET NAME' column\n",
    "dfspecified['ON STREET NAME'] = dfspecified['ON STREET NAME'].apply(standardize_street_name)\n",
    "dfspecified['CROSS STREET NAME'] = dfspecified['CROSS STREET NAME'].apply(standardize_street_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHuk3xIBYOFc"
   },
   "outputs": [],
   "source": [
    "dfspecified['CRASH DATE'] = pd.to_datetime(dfspecified['CRASH DATE'])\n",
    "dfspecified['DAY_OF_WEEK'] = dfspecified['CRASH DATE'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5lJ5TYpYdrg"
   },
   "outputs": [],
   "source": [
    "def get_season(date):\n",
    "    month = date.month\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "    else:\n",
    "        return 'Winter'\n",
    "\n",
    "dfspecified['SEASON'] = dfspecified['CRASH DATE'].apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAjefYM_ForF"
   },
   "outputs": [],
   "source": [
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 1'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 1'].apply(lambda x: \"Cell Phone\" if \"Cell Phone\" in x else x)\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 1'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 1'].apply(lambda x: \"Drugs\" if \"Drugs\" in x else x)\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 1'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 1'].apply(lambda x: \"Illness\" if \"Illnes\" in x else x)\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 1'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 1'].apply(lambda x: \"Cell Phone\" if \"Texting\" in x else x)\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 1'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 1'].apply(lambda x: \"Reaction to Uninvolved Vehicle\" if \"Reaction to\" in x else x)\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 1'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 1'].apply(lambda x: \"Pavement Issues\" if \"Pavement\" in x else x)\n",
    "\n",
    "\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 2'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 2'].apply(lambda x: \"Cell Phone\" if \"Cell Phone\" in x else x)\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 2'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 2'].apply(lambda x: \"Drugs\" if \"Drugs\" in x else x)\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 2'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 2'].apply(lambda x: \"Illness\" if \"Illnes\" in x else x)\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 2'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 2'].apply(lambda x: \"Cell Phone\" if \"Texting\" in x else x)\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 2'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 2'].apply(lambda x: \"Reaction to Uninvolved Vehicle\" if \"Reaction to\" in x else x)\n",
    "dfspecified['CONTRIBUTING FACTOR VEHICLE 2'] = dfspecified['CONTRIBUTING FACTOR VEHICLE 2'].apply(lambda x: \"Pavement Issues\" if \"Pavement\" in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImVdIDWQcjv_"
   },
   "outputs": [],
   "source": [
    "# Group the data by location (intersections) and calculate the accident frequency\n",
    "accident_frequency = dfspecified.groupby(['ON STREET NAME', 'CROSS STREET NAME']).size().reset_index(name='ACCIDENT_COUNT')\n",
    "\n",
    "# Sort the data by accident frequency in descending order\n",
    "accident_frequency_sorted = accident_frequency.sort_values('ACCIDENT_COUNT', ascending=False)\n",
    "\n",
    "# Display the accident frequency by location\n",
    "accident_frequency_sorted.head()\n",
    "\n",
    "# Merge the accident_frequency_sorted back to the original DataFrame\n",
    "dfspecified = dfspecified.merge(accident_frequency_sorted, on=['ON STREET NAME', 'CROSS STREET NAME'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNW_pbyVY155",
    "outputId": "ad81cf53-0989-44cf-b6d9-822c3d44509d"
   },
   "outputs": [],
   "source": [
    "dfspecified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jOkBgiKSngG",
    "outputId": "78f79ce8-d3b1-460f-c24a-4eb469a2ff64"
   },
   "outputs": [],
   "source": [
    "dfspecified.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZkoxwhaYo23"
   },
   "outputs": [],
   "source": [
    "import geohash\n",
    "\n",
    "# Let's assume df is your DataFrame and it has columns 'latitude' and 'longitude'\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Compute geohashes\n",
    "def safe_encode(latitude, longitude, precision=6):\n",
    "    try:\n",
    "        return geohash.encode(latitude, longitude, precision)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Compute geohashes\n",
    "dfspecified['geohash'] = dfspecified.apply(lambda row: safe_encode(row['LATITUDE'], row['LONGITUDE'], precision=7), axis=1)\n",
    "\n",
    "# Find out which coordinates fall into a specific region\n",
    "specific_region = 'geohash_of_interest'\n",
    "df_in_specific_region = dfspecified[dfspecified['geohash'] == specific_region]\n",
    "\n",
    "# Count the number of distinct geohashes\n",
    "num_distinct_geohashes = dfspecified['geohash'].nunique()\n",
    "\n",
    "print(f\"Number of distinct geohashes: {num_distinct_geohashes}\")\n",
    "\n",
    "# To find the count of coordinates in each geohash\n",
    "geohash_counts = dfspecified['geohash'].value_counts()\n",
    "print(geohash_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMzxN4vphReF",
    "outputId": "75a5cdc1-160d-4ec8-df9c-07ab149c3316"
   },
   "outputs": [],
   "source": [
    "uniqueGeo = dfspecified['geohash'].nunique()\n",
    "\n",
    "print(uniqueGeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50uSkX1-ZNP8",
    "outputId": "bdfa33ee-e186-46ca-bf6d-fa6fa5234e0b"
   },
   "outputs": [],
   "source": [
    "num_distinct_values = df['ZIP CODE'].nunique()\n",
    "\n",
    "print(num_distinct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "HSyczL86kln_",
    "outputId": "d68f2de8-522e-496e-9d9e-75a6f8147135"
   },
   "outputs": [],
   "source": [
    "dfspecified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "Zx951SLg2Oi0",
    "outputId": "71487a40-b303-4352-b531-a3cb4954189b"
   },
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = dfspecified.corr()\n",
    "\n",
    "# Plot a heatmap of the correlation matrix\n",
    "import seaborn as sns\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uUSbgx-1j6oP",
    "outputId": "583b5f40-bcb3-4753-ef00-f2add49460bc"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(dfspecified['CONTRIBUTING FACTOR VEHICLE 1'], dfspecified['CONTRIBUTING FACTOR VEHICLE 2'])\n",
    "\n",
    "# Perform chi-squared test\n",
    "chi2, p, dof, ex = chi2_contingency(contingency_table)\n",
    "\n",
    "# Calculate Cramér's V\n",
    "n = contingency_table.sum().sum()\n",
    "cramer_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))\n",
    "\n",
    "print(f\"Cramér's V: {cramer_v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "id": "H78SCR7sBy6M",
    "outputId": "2e7d0c22-eb5c-4a26-a4b3-94a698a57c4f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count occurrences of each contributing factor\n",
    "factor_counts = dfspecified['CONTRIBUTING FACTOR VEHICLE 1'].value_counts()\n",
    "\n",
    "# Create a bar chart of the counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "factor_counts.plot(kind='bar')\n",
    "plt.title('Frequency of Contributing Factors in NYC Car Accidents')\n",
    "plt.xlabel('Contributing Factor')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSqAUSJh-3P-"
   },
   "source": [
    "**Based on the identified causes, preventive measures can be determined. For example, if \"Driver Inattention/Distraction\" is a common cause, measures can be taken to reduce distractions while driving, such as implementing stricter laws on using mobile phones while driving or providing education on the dangers of distracted driving.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "j3m6pYChCdVD",
    "outputId": "3402e4da-a40c-4040-962c-1970a0b3e0df"
   },
   "outputs": [],
   "source": [
    "# Group the data by hour of day and sum the number of injured persons\n",
    "df_hourly = dfspecified.groupby(dfspecified['CRASH TIME'].dt.hour)['NUMBER OF PERSONS INJURED'].sum().reset_index()\n",
    "\n",
    "# Create a line chart\n",
    "plt.plot(df_hourly['CRASH TIME'], df_hourly['NUMBER OF PERSONS INJURED'])\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Number of Injured Persons')\n",
    "plt.title('Number of Injured Persons by Hour of Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Hd5tIvYmCuTC",
    "outputId": "380add53-5456-4e84-b20d-a661c6e443cb"
   },
   "outputs": [],
   "source": [
    "weekday_counts = dfspecified.groupby('DAY_OF_WEEK')['CRASH DATE'].count()\n",
    "\n",
    "weekday_counts.index = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "plt.bar(weekday_counts.index, weekday_counts.values)\n",
    "plt.title('Number of Accidents by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "aNLzDh8kCqVO",
    "outputId": "6b66d4d4-f858-4831-81d2-8c5d7ad4c2bb"
   },
   "outputs": [],
   "source": [
    "# Group the data by ON STREET NAME and CROSS STREET NAME to find the number of accidents at each intersection\n",
    "dangerous_intersections = dfspecified.groupby(['ON STREET NAME', 'CROSS STREET NAME']).size().reset_index(name='ACCIDENT_COUNT')\n",
    "\n",
    "# Sort the intersections by the number of accidents in descending order\n",
    "dangerous_intersections = dangerous_intersections.sort_values('ACCIDENT_COUNT', ascending=False)\n",
    "\n",
    "# Display the top 10 most dangerous intersections\n",
    "dangerous_intersections.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzsRxZb5EsWD",
    "outputId": "0f4bd622-9f87-4829-ba41-3ce987f8d899"
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to only include intersection crashes\n",
    "df_intersections = dfspecified[(dfspecified['ON STREET NAME'].notnull()) & (dfspecified['CROSS STREET NAME'].notnull())]\n",
    "\n",
    "# Group the data by intersection and count the number of crashes at each intersection\n",
    "df_intersection_counts = df_intersections.groupby(['ON STREET NAME', 'CROSS STREET NAME']).size().reset_index(name='Crash Count')\n",
    "\n",
    "# Sort the intersections by the number of crashes to identify the most dangerous intersections\n",
    "df_intersection_counts = df_intersection_counts.sort_values('Crash Count', ascending=False)\n",
    "\n",
    "# Display the top 10 most dangerous intersections\n",
    "print(df_intersection_counts.head(10))\n",
    "\n",
    "# For each intersection, analyze the contributing factors to identify the main causes of crashes\n",
    "for i, row in df_intersection_counts.head(10).iterrows():\n",
    "    intersection = row['ON STREET NAME'] + ' and ' + row['CROSS STREET NAME']\n",
    "    print('\\nIntersection:', intersection)\n",
    "\n",
    "    # Filter the data to only include crashes at this intersection\n",
    "    df_intersection_crashes = df_intersections[(df_intersections['ON STREET NAME'] == row['ON STREET NAME']) & (df_intersections['CROSS STREET NAME'] == row['CROSS STREET NAME'])]\n",
    "\n",
    "    # Group the crashes by contributing factor and count the number of crashes for each factor\n",
    "    df_intersection_contributing_factors = df_intersection_crashes.groupby('CONTRIBUTING FACTOR VEHICLE 1').size().reset_index(name='Crash Count')\n",
    "\n",
    "    # Sort the contributing factors by the number of crashes to identify the main causes of crashes at this intersection\n",
    "    df_intersection_contributing_factors = df_intersection_contributing_factors.sort_values('Crash Count', ascending=False)\n",
    "\n",
    "    # Display the top contributing factors for this intersection\n",
    "    print('Top Contributing Factors:')\n",
    "    print(df_intersection_contributing_factors.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "id": "DsgBggEtEn9y",
    "outputId": "fdd0c464-809b-42e9-fac5-e9652828d67c"
   },
   "outputs": [],
   "source": [
    "# Get the top 10 most dangerous intersections\n",
    "top_10 = df_intersection_counts.head(10)\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(top_10['ON STREET NAME'] + ' & ' + top_10['CROSS STREET NAME'], top_10['Crash Count'])\n",
    "\n",
    "# Set the title and labels\n",
    "ax.set_title('Top 10 Most Dangerous Intersections in NYC', fontsize=16)\n",
    "ax.set_xlabel('Number of Crashes')\n",
    "ax.set_ylabel('Intersection')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cX8yDfUPIlvH",
    "outputId": "25927b50-5a1d-437b-8221-158c26339bd3"
   },
   "outputs": [],
   "source": [
    "# Define a function to plot stacked horizontal bar chart for top 10 dangerous intersections\n",
    "def plot_top_intersection(intersection_name):\n",
    "    # Filter the data to include only the selected intersection\n",
    "    df_intersection = df_intersections[(df_intersections['ON STREET NAME'] == intersection_name[0]) & (df_intersections['CROSS STREET NAME'] == intersection_name[1])]\n",
    "\n",
    "    # Group the data by contributing factor and count the number of crashes caused by each factor\n",
    "    df_factor_counts = df_intersection.groupby('CONTRIBUTING FACTOR VEHICLE 1').size().reset_index(name='Count')\n",
    "\n",
    "    # Sort the contributing factors by count in descending order\n",
    "    df_factor_counts = df_factor_counts.sort_values('Count', ascending=False)\n",
    "\n",
    "    # Create a horizontal stacked bar chart\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    y_pos = np.arange(len(df_factor_counts))\n",
    "    ax.barh(y_pos, df_factor_counts['Count'], align='center', color='steelblue')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(df_factor_counts['CONTRIBUTING FACTOR VEHICLE 1'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Number of Accidents')\n",
    "    ax.set_title('Contributing Factors for Accidents at '+intersection_name[0]+' and '+intersection_name[1])\n",
    "    plt.show()\n",
    "\n",
    "# Loop through the top 10 intersections and plot a stacked bar chart for each intersection\n",
    "for intersection in df_intersection_counts.head(10).itertuples(index=False):\n",
    "    plot_top_intersection((intersection[0], intersection[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrN5G5jm5Q1N",
    "outputId": "10657b97-5318-4ad9-cc35-1e6c1f9dbf9c"
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to only include crashes with non-null vehicle types\n",
    "df_vehicle_types = dfspecified[dfspecified['VEHICLE TYPE CODE 1'].notnull()]\n",
    "\n",
    "# Group the data by vehicle type and count the number of crashes for each type\n",
    "df_vehicle_counts = df_vehicle_types.groupby('VEHICLE TYPE CODE 1').size().reset_index(name='Crash Count')\n",
    "\n",
    "# Sort the vehicle types by the number of crashes to identify which types are most commonly involved in accidents\n",
    "df_vehicle_counts = df_vehicle_counts.sort_values('Crash Count', ascending=False)\n",
    "\n",
    "# Display the top 10 most commonly involved vehicle types\n",
    "print(df_vehicle_counts.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "L1Sl3hJy5XhO",
    "outputId": "e0b6ddbd-2858-4ccf-928e-44d2611ef29b"
   },
   "outputs": [],
   "source": [
    "# Create a bar chart of the top 10 most commonly involved vehicle types\n",
    "plt.bar(df_vehicle_counts['VEHICLE TYPE CODE 1'].head(10), df_vehicle_counts['Crash Count'].head(10))\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Vehicle Type')\n",
    "plt.ylabel('Number of Crashes')\n",
    "plt.title('Top 10 Most Commonly Involved Vehicle Types')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "R9OMyi9Y7l0R",
    "outputId": "a939962c-cf2e-47b0-c2a2-6db195d3072f"
   },
   "outputs": [],
   "source": [
    "# Extract the year from the CRASH DATE column\n",
    "dfspecified['Year'] = dfspecified['CRASH DATE'].dt.year\n",
    "\n",
    "# Count the number of crashes per year\n",
    "crashes_by_year = dfspecified.groupby('Year').size()\n",
    "\n",
    "# Create a line graph showing the number of crashes per year\n",
    "plt.plot(crashes_by_year.index, crashes_by_year.values)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Crashes')\n",
    "plt.title('Crashes by Year in NYC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "ebPNTzbi8ukI",
    "outputId": "75770e50-e3ba-4f3f-bdcb-1412882c0784"
   },
   "outputs": [],
   "source": [
    "# Group the data by year and calculate the number of crashes and fatalities in each year\n",
    "df_yearly = dfspecified.groupby(dfspecified['CRASH DATE'].dt.year)[['NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED']].sum().reset_index()\n",
    "\n",
    "# Calculate the crash rate and injury rate for each year\n",
    "df_yearly['Total Crashes'] = df_yearly['NUMBER OF PERSONS INJURED'] + df_yearly['NUMBER OF PERSONS KILLED']\n",
    "df_yearly['Crash Rate'] = df_yearly['Total Crashes'] / dfspecified['CRASH DATE'].dt.year.value_counts().sort_index()\n",
    "df_yearly['Injury Rate'] = df_yearly['NUMBER OF PERSONS INJURED'] / dfspecified['CRASH DATE'].dt.year.value_counts().sort_index()\n",
    "\n",
    "# Calculate the fatal rate for each year\n",
    "df_yearly['Fatal Rate'] = df_yearly['NUMBER OF PERSONS KILLED'] / df_yearly['Total Crashes']\n",
    "\n",
    "# Plot the fatal rate by year\n",
    "plt.plot(df_yearly['CRASH DATE'], df_yearly['Fatal Rate'])\n",
    "plt.title('Fatal Rate by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Fatal Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIkzAjauAUog"
   },
   "source": [
    "**How has the implementation of Vision Zero policies in NYC affected the frequency and severity of car accidents, and what more can be done to improve road safety in the city?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "mGMmOcAD_cOv",
    "outputId": "bd7432d2-60e9-4d0c-fe96-0ca226594743"
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to only include crashes that occurred after the implementation of Vision Zero policies\n",
    "df_vz = dfspecified[dfspecified['CRASH DATE'].dt.year >= 2014]\n",
    "\n",
    "# Group the data by year and count the number of crashes, injuries, and fatalities for each year\n",
    "df_vz_yearly = df_vz.groupby(df_vz['CRASH DATE'].dt.year)[['CRASH DATE']].count().rename(columns={'CRASH DATE': 'Crashes'})\n",
    "df_vz_yearly['Injuries'] = df_vz.groupby(df_vz['CRASH DATE'].dt.year)[['NUMBER OF PERSONS INJURED']].sum()\n",
    "df_vz_yearly['Fatalities'] = df_vz.groupby(df_vz['CRASH DATE'].dt.year)[['NUMBER OF PERSONS KILLED']].sum()\n",
    "\n",
    "# Calculate the crash, injury, and fatality rates per capita for each year\n",
    "population = [ 8550405, 8622698, 8669675, 8622698, 8537673, 8468181, 8398748, 8326699, 8253213, 8175133]\n",
    "df_vz_yearly['Crash Rate'] = df_vz_yearly['Crashes'] / population\n",
    "df_vz_yearly['Injury Rate'] = df_vz_yearly['Injuries'] / population\n",
    "df_vz_yearly['Fatality Rate'] = df_vz_yearly['Fatalities'] / population\n",
    "\n",
    "# Plot the trends for the crash, injury, and fatality rates over time\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(df_vz_yearly.index, df_vz_yearly['Crash Rate'], label='Crash Rate')\n",
    "ax.plot(df_vz_yearly.index, df_vz_yearly['Injury Rate'], label='Injury Rate')\n",
    "ax.plot(df_vz_yearly.index, df_vz_yearly['Fatality Rate'], label='Fatality Rate')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Rate per capita')\n",
    "ax.set_title('Trends in crash, injury, and fatality rates after Vision Zero policies')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "Bshdy7AIGnSD",
    "outputId": "fac131ba-dff9-4bea-ede3-db51e9472f4f"
   },
   "outputs": [],
   "source": [
    "# Group the data by borough and injury severity, and count the number of accidents in each group\n",
    "grouped_data = dfspecified.groupby(['BOROUGH', 'INJURY_CATEGORY']).size().unstack()\n",
    "\n",
    "# Create a bar chart\n",
    "ax = grouped_data.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Set the title and axis labels\n",
    "ax.set_title('Number of Accidents by Borough and Severity')\n",
    "ax.set_xlabel('Borough')\n",
    "ax.set_ylabel('Number of Accidents')\n",
    "\n",
    "# Set the x-tick labels to the borough names\n",
    "ax.set_xticklabels(grouped_data.index, rotation=0)\n",
    "\n",
    "# Use different colors for each injury severity level\n",
    "ax.legend(title='Injury Severity', loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "qJonL7zfpTZL",
    "outputId": "ab975176-e713-480d-e491-e1a806ffddc0"
   },
   "outputs": [],
   "source": [
    "# Calculate the number of accidents per season\n",
    "season_counts = dfspecified.groupby('SEASON')['SEASON'].count()\n",
    "\n",
    "# Plot a bar graph\n",
    "sns.barplot(x=season_counts.index, y=season_counts.values)\n",
    "\n",
    "# Set the plot title and labels\n",
    "plt.title('Number of Accidents per Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "tFDMoEIFrHcA",
    "outputId": "939c3b4c-f35f-464e-88e7-b88c00509e81"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Group the data by season and injury category\n",
    "seasonal_injuries = dfspecified.groupby(['SEASON', 'INJURY_CATEGORY']).size().reset_index(name='count')\n",
    "\n",
    "# Pivot the data to create a table with seasons as rows, injury categories as columns, and counts as values\n",
    "seasonal_injuries_pivot = seasonal_injuries.pivot(index='SEASON', columns='INJURY_CATEGORY', values='count')\n",
    "\n",
    "# Normalize the data by row (i.e., divide each row by the sum of its values)\n",
    "seasonal_injuries_pivot_norm = seasonal_injuries_pivot.div(seasonal_injuries_pivot.sum(axis=1), axis=0)\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "sns.set_style('whitegrid')\n",
    "ax = seasonal_injuries_pivot_norm.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "ax.set_xlabel('Season')\n",
    "ax.set_ylabel('Proportion of injuries')\n",
    "ax.set_title('Distribution of injuries across seasons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "DZAWUYa_rLMG",
    "outputId": "426ef3c3-18a2-456b-e708-d501b607fef0"
   },
   "outputs": [],
   "source": [
    "# Create a subset of the data with only the columns we need\n",
    "dfspecified['MONTH'] = dfspecified['CRASH DATE'].dt.month\n",
    "\n",
    "df_injury = dfspecified[['MONTH', 'INJURY_CATEGORY']]\n",
    "\n",
    "# Group the data by month and injury category, and count the number of occurrences\n",
    "df_injury_counts = df_injury.groupby(['MONTH', 'INJURY_CATEGORY']).size().reset_index(name='COUNTS')\n",
    "\n",
    "# Pivot the data to create a matrix of injury category counts for each month\n",
    "df_injury_pivot = df_injury_counts.pivot(index='MONTH', columns='INJURY_CATEGORY', values='COUNTS').fillna(0)\n",
    "\n",
    "# Create the bar plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = df_injury_pivot.plot(kind='bar', stacked=True, figsize=(12,6))\n",
    "ax.set_title(\"Injury Categories by Month\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ebXzEc86sI2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Drop irrelevant columns\n",
    "data = dfspecified[['BOROUGH', 'DAY_OF_WEEK', 'SECONDS_SINCE_MIDNIGHT', 'SEASON', 'ACCIDENT_COUNT', 'CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2','VEHICLE TYPE CODE 1','VEHICLE TYPE CODE 2','INJURY_CATEGORY']]\n",
    "\n",
    "# Convert categorical columns to numerical using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "data['CONTRIBUTING FACTOR VEHICLE 1'] = le.fit_transform(dfspecified['CONTRIBUTING FACTOR VEHICLE 1'])\n",
    "data['CONTRIBUTING FACTOR VEHICLE 2'] = le.fit_transform(dfspecified['CONTRIBUTING FACTOR VEHICLE 2'])\n",
    "data['VEHICLE TYPE CODE 1'] = le.fit_transform(dfspecified['VEHICLE TYPE CODE 1'])\n",
    "data['VEHICLE TYPE CODE 2'] = le.fit_transform(dfspecified['VEHICLE TYPE CODE 2'])\n",
    "data['BOROUGH'] = le.fit_transform(dfspecified['BOROUGH'])\n",
    "data['SEASON'] = le.fit_transform(dfspecified['SEASON'])\n",
    "data['DAY_OF_WEEK'] = le.fit_transform(dfspecified['DAY_OF_WEEK'])\n",
    "data['INJURY_CATEGORY_ENCODED'] = le.fit_transform(data['INJURY_CATEGORY'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StiDaxb56wFp"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X = data.drop(['INJURY_CATEGORY_ENCODED','INJURY_CATEGORY'], axis=1)\n",
    "y = data['INJURY_CATEGORY_ENCODED']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3F3bQqyc_HD"
   },
   "outputs": [],
   "source": [
    "def model_performance_analysis(number, model, X_test, y_test):\n",
    "    # Predict labels for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Mean squared error: {mse}\")\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_test, y_pred, zero_division=1)\n",
    "    print(report)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    # Create a new figure for the matrix\n",
    "    plt.figure(i)\n",
    "\n",
    "    # Plot the matrix\n",
    "    plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "    plt.title(f\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0, 1, 2, 3, 4], [\"No Injury\", \"Mild Injury\", \"Moderate Injury\", \"Severe Injury\", \"Fatal\"])\n",
    "    plt.yticks([0, 1, 2, 3, 4], [\"No Injury\", \"Mild Injury\", \"Moderate Injury\", \"Severe Injury\", \"Fatal\"])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    #sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f89U46Q8WP4-",
    "outputId": "0908ae6d-6433-49e6-dc9a-6428a92f3c78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the models to be evaluated\n",
    "models = [\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    LogisticRegression(max_iter=10000),\n",
    "    MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
    "]\n",
    "\n",
    "# Perform cross-validation\n",
    "i=0\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{model.__class__.__name__}\")\n",
    "    model_performance_analysis(i,model, X_test, y_test)\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"{model.__class__.__name__} Accuracy: {scores.mean()} +/- {scores.std()}\")\n",
    "    i=i+1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
